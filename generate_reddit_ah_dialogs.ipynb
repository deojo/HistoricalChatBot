{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4193d395",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "2bba9749f6334f59af61b76693e0c5c5",
            "9d04208d435f4f7682f185a06edc20ab",
            "1855201e9c3b4b90802a04ffe6de786e",
            "a20f09387d1843459ad76eadaa1f5b0f",
            "2c86fadab2bf41839e906935a74e1c6b"
          ]
        },
        "id": "4193d395",
        "outputId": "eb7edd6d-d223-4c2d-d318-cda5bb4abd8b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Found cached dataset parquet (/Users/ninaadj/.cache/huggingface/datasets/Deojoandco___parquet/Deojoandco--reddit_ah_v3-c0f56124ceee8b0c/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2bba9749f6334f59af61b76693e0c5c5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['url', 'id', 'num_comments', 'name', 'title', 'body', 'score', 'upvote_ratio', 'distinguished', 'over_18', 'created_utc', 'comments', 'best_num_comments'],\n",
            "        num_rows: 2598\n",
            "    })\n",
            "})\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9d04208d435f4f7682f185a06edc20ab",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Creating Dialog:   0%|          | 0/2598 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID cb24421fbf69d81c2b449c3743d07d60 in your message.).\n",
            "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised APIError: Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Mon, 05 Jun 2023 13:31:21 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '7d28be78db632e23-BOM', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n",
            "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID eb506a75bc8289b6311a064457dae96b in your message.).\n",
            "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 1a01b2af6bb26b6920fd44e22a3a63eb in your message.).\n",
            "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID e33bcd0143371c18139d5ea89702e128 in your message.).\n",
            "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 2a8cdc87f1b77bcd8a8617975109eddd in your message.).\n",
            "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised APIError: Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Mon, 05 Jun 2023 21:18:02 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '7d2b69bb68a829ea-BOM', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n",
            "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=600).\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1855201e9c3b4b90802a04ffe6de786e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Pushing dataset shards to the dataset hub:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a20f09387d1843459ad76eadaa1f5b0f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Creating parquet from Arrow format:   0%|          | 0/3 [00:00<?, ?ba/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2c86fadab2bf41839e906935a74e1c6b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Upload 1 LFS files:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\"\"\"\n",
        "Created on Thu Jun  1 10:11:35 2023\n",
        "@author: DSJoshi\n",
        "\"\"\"\n",
        "\n",
        "from datasets import load_dataset\n",
        "import os\n",
        "import pandas as pd\n",
        "import datasets\n",
        "import json\n",
        "from tqdm.notebook import tqdm_notebook\n",
        "\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain import PromptTemplate, LLMChain\n",
        "from langchain.prompts.chat import (\n",
        "    ChatPromptTemplate,\n",
        "    SystemMessagePromptTemplate,\n",
        "    AIMessagePromptTemplate,\n",
        "    HumanMessagePromptTemplate,\n",
        ")\n",
        "from langchain.schema import (\n",
        "    AIMessage,\n",
        "    HumanMessage,\n",
        "    SystemMessage\n",
        ")\n",
        "import openai\n",
        "import backoff  # for exponential backoff\n",
        "\n",
        "@backoff.on_exception(backoff.expo, openai.error.RateLimitError)\n",
        "def get_dialog_turns(chat, prompt, query_text):\n",
        "    dialog_response= {}\n",
        "    dialog_response['Error'] = ''\n",
        "    try:\n",
        "        messages = [\n",
        "            SystemMessage(content=prompt),\n",
        "            HumanMessage(content=query_text)\n",
        "        ]\n",
        "\n",
        "        dialog_message = chat(messages)\n",
        "        dialog_response['text'] = dialog_message.content\n",
        "        dialog_response['success'] = True\n",
        "    except Exception as e:\n",
        "        dialog_response['text'] = ''\n",
        "        dialog_response['success'] = True\n",
        "        dialog_response['Error'] = str(e)\n",
        "\n",
        "    return dialog_response\n",
        "\n",
        "\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] =  \"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\"\n",
        "\n",
        "def get_dialog_query(record):\n",
        "\n",
        "    query_text = record['title']\n",
        "\n",
        "    body = record['body'].strip()\n",
        "\n",
        "    if len(body) > 0:\n",
        "        query_text = query_text + '\\n' + body\n",
        "\n",
        "    comments = ''\n",
        "    for comment in record['comments']:\n",
        "        if len(comments) > 0:\n",
        "            comments += '\\n'\n",
        "        comments += comment['body']\n",
        "\n",
        "    query_text = query_text + '\\n' + comments\n",
        "\n",
        "    return query_text\n",
        "\n",
        "ds = load_dataset('Deojoandco/reddit_ah_v3')\n",
        "print(ds)\n",
        "\n",
        "chat = ChatOpenAI(temperature=0.7, max_tokens=2048)\n",
        "\n",
        "prompt = \"Create a 2 person instructional Q&A dialog, where person 1 is asking question and person 2 is answering, from the following passsage. Include atleast 3 turns per person.\"\n",
        "\n",
        "records = []\n",
        "\n",
        "pbar = tqdm_notebook(ds['train'], desc='Creating Dialog')\n",
        "for i, record in enumerate(pbar):\n",
        "    query_text = get_dialog_query(record)\n",
        "\n",
        "    dialog_message_text = ''\n",
        "    dialog_success = None\n",
        "    dialog_error = ''\n",
        "\n",
        "    try:\n",
        "        dialog_response = get_dialog_turns(chat, prompt, query_text)\n",
        "        dialog_message_text = dialog_response['text']\n",
        "        dialog_success = True\n",
        "    except Exception as e:\n",
        "        dialog_success = False\n",
        "        dialog_error = str(e)\n",
        "\n",
        "    record['query'] = prompt + '\\n' + query_text\n",
        "    record['dialog'] = dialog_message_text\n",
        "    record['dialog_success'] = dialog_success\n",
        "    records.append(record)\n",
        "\n",
        "    with open(f'ah_openai_dialog_df_append_v3.json', 'a') as outfile:\n",
        "        json_text = json.dumps(record)\n",
        "        outfile.write(json_text + \"\\n\")\n",
        "\n",
        "\n",
        "ds = pd.DataFrame(data=records)\n",
        "ds.to_json('ah_openai_dialog_df_v3.json')\n",
        "\n",
        "hds = datasets.Dataset.from_pandas(ds)\n",
        "hds.push_to_hub('ah_openai_dialog_v3', token ='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')\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}